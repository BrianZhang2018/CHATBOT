# ğŸ¯ Fine-tuning System Documentation

## ğŸ“– Overview

This document explains the **Fine-tuning System** for our local chatbot project. The fine-tuning system allows you to train custom models on your conversation data to improve performance for specific use cases and domains.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conversation    â”‚â”€â”€â”€â–¶â”‚ Data Collection â”‚â”€â”€â”€â–¶â”‚ Data Preparationâ”‚
â”‚ Data            â”‚    â”‚ & Cleaning      â”‚    â”‚ & Formatting    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                        â”‚
                              â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Model Training  â”‚â”€â”€â”€â–¶â”‚ Model Evaluationâ”‚
                       â”‚ (LoRA/QLoRA)    â”‚    â”‚ & Comparison    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                        â”‚
                              â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Model Deploymentâ”‚â”€â”€â”€â–¶â”‚ Integration     â”‚
                       â”‚ to Ollama       â”‚    â”‚ with Chatbot    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ How Fine-tuning Works

### **1. Data Collection Pipeline**

```
Conversations â†’ Logging â†’ Cleaning â†’ Filtering â†’ Export
```

#### **Step 1: Conversation Logging**
- **Automatic Logging**: Conversations from the chatbot UI are automatically logged
- **Manual Export**: Export existing chat history for fine-tuning
- **Format**: JSONL format with metadata

#### **Step 2: Data Cleaning**
- **Text Normalization**: Remove URLs, emails, phone numbers
- **Whitespace Handling**: Normalize spaces and newlines
- **Content Filtering**: Remove inappropriate or repetitive content

#### **Step 3: Data Filtering**
- **Length Filtering**: Remove too short or too long conversations
- **Quality Filtering**: Remove low-quality or duplicate conversations
- **Validation**: Ensure conversations meet quality criteria

#### **Step 4: Data Export**
- **Multiple Formats**: Export to ChatML, Alpaca, Instruction formats
- **Statistics**: Generate detailed statistics about the data
- **Validation**: Ensure exported data is ready for training

### **2. Data Preparation Pipeline**

```
Raw Data â†’ Formatting â†’ Tokenization â†’ Dataset Creation
```

#### **Step 1: Data Formatting**
- **ChatML Format**: Standard format for many fine-tuning frameworks
- **Alpaca Format**: Instruction-following format
- **Instruction Format**: Simple instruction-response format

#### **Step 2: Tokenization**
- **Tokenizer Loading**: Load appropriate tokenizer for the base model
- **Text Tokenization**: Convert text to token IDs
- **Length Management**: Handle sequence length limits

#### **Step 3: Dataset Creation**
- **Training Split**: Split data into train/validation/test sets
- **Dataset Building**: Create PyTorch datasets
- **Validation**: Ensure datasets are properly formatted

### **3. Training Pipeline**

```
Dataset â†’ Model Loading â†’ LoRA/QLoRA â†’ Training â†’ Saving
```

#### **Step 1: Model Loading**
- **Base Model**: Load pre-trained model (e.g., Mistral, Llama)
- **Tokenizer**: Load corresponding tokenizer
- **Configuration**: Set up training parameters

#### **Step 2: LoRA/QLoRA Setup**
- **LoRA**: Low-Rank Adaptation for efficient fine-tuning
- **QLoRA**: Quantized LoRA for memory efficiency
- **Parameter Selection**: Choose which layers to adapt

#### **Step 3: Training**
- **Batch Processing**: Process data in batches
- **Loss Calculation**: Calculate training and validation loss
- **Optimization**: Update model parameters
- **Monitoring**: Track training progress

#### **Step 4: Model Saving**
- **Checkpointing**: Save model checkpoints
- **Final Model**: Save the final fine-tuned model
- **Metadata**: Save training configuration and results

### **4. Evaluation Pipeline**

```
Test Data â†’ Model Testing â†’ Metrics Calculation â†’ Comparison
```

#### **Step 1: Model Testing**
- **Test Prompts**: Use predefined test prompts
- **Response Generation**: Generate responses from fine-tuned model
- **Quality Assessment**: Evaluate response quality

#### **Step 2: Metrics Calculation**
- **Perplexity**: Measure model uncertainty
- **Accuracy**: Measure response accuracy
- **BLEU/Rouge**: Measure text similarity

#### **Step 3: Model Comparison**
- **Base Model**: Compare with original model
- **Previous Models**: Compare with previous fine-tuned models
- **Performance Analysis**: Analyze improvements

### **5. Deployment Pipeline**

```
Fine-tuned Model â†’ Conversion â†’ Ollama Integration â†’ Testing
```

#### **Step 1: Model Conversion**
- **GGUF Conversion**: Convert to GGUF format for Ollama
- **Modelfile Creation**: Create Ollama modelfile
- **Model Registration**: Register model with Ollama

#### **Step 2: Integration**
- **Model Switching**: Switch between base and fine-tuned models
- **Performance Testing**: Test model performance
- **User Interface**: Update UI to show available models

## ğŸ“ File Structure

```
fine_tuning/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ fine_tuning_config.yaml     # Fine-tuning configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ conversations/              # Raw conversation data
â”‚   â”œâ”€â”€ processed/                  # Processed training data
â”‚   â””â”€â”€ evaluation/                 # Evaluation datasets
â”œâ”€â”€ data_collection/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conversation_logger.py      # Log conversations from UI
â”‚   â”œâ”€â”€ data_export.py              # Export chat history
â”‚   â””â”€â”€ data_cleaner.py             # Clean and filter data
â”œâ”€â”€ data_preparation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ formatter.py                # Format data for training
â”‚   â”œâ”€â”€ tokenizer.py                # Tokenization utilities
â”‚   â””â”€â”€ dataset_builder.py          # Build training datasets
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lora_trainer.py             # LoRA fine-tuning
â”‚   â”œâ”€â”€ qlora_trainer.py            # QLoRA fine-tuning
â”‚   â””â”€â”€ trainer_utils.py            # Training utilities
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py                  # Evaluation metrics
â”‚   â”œâ”€â”€ evaluator.py                # Model evaluation
â”‚   â””â”€â”€ comparison.py               # Compare models
â”œâ”€â”€ model_management/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_deployer.py           # Deploy fine-tuned models
â”‚   â”œâ”€â”€ model_switcher.py           # Switch between models
â”‚   â””â”€â”€ model_registry.py           # Model registry
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ streamlit_fine_tuning.py    # Streamlit integration
â”‚   â””â”€â”€ ollama_integration.py       # Ollama integration
â”œâ”€â”€ test_fine_tuning.py             # Test fine-tuning pipeline
â”œâ”€â”€ requirements.txt                # Fine-tuning dependencies
â””â”€â”€ README.md                       # This file
```

## ğŸ¯ Key Components

### **1. Conversation Logger (`conversation_logger.py`)**
```python
# Logs conversations for fine-tuning data collection
logger = ConversationLogger("conversations.jsonl")
logger.log_conversation(user_message, bot_response, metadata)
```

**Features:**
- Automatic conversation logging
- Session-based logging
- Statistics generation
- Export functionality

### **2. Data Cleaner (`data_cleaner.py`)**
```python
# Cleans and filters conversation data
cleaner = DataCleaner(min_length=10, max_length=1000)
cleaned_data = cleaner.filter_conversations(conversations)
```

**Features:**
- Text normalization
- Content filtering
- Duplicate removal
- Quality validation

### **3. Training Data Formatter (`formatter.py`)**
```python
# Formats data for different fine-tuning frameworks
formatter = TrainingDataFormatter("chatml")
training_pairs = formatter.create_training_pairs(conversations)
```

**Features:**
- Multiple format support (ChatML, Alpaca, Instruction)
- Format validation
- Batch processing
- Format conversion

### **4. Tokenizer Utils (`tokenizer.py`)**
```python
# Handles tokenization for fine-tuning
tokenizer = TokenizerUtils("microsoft/DialoGPT-medium")
tokenized = tokenizer.tokenize_conversation(user_msg, bot_response)
```

**Features:**
- Multiple tokenizer support
- Token counting
- Batch tokenization
- Token estimation

## âš™ï¸ Configuration

### **Fine-tuning Configuration (`fine_tuning_config.yaml`)**
```yaml
# Data collection
data_collection:
  log_file: "conversations.jsonl"
  min_conversation_length: 10
  max_conversation_length: 1000
  auto_export: true
  export_interval: 100

# Data preparation
data_preparation:
  format_type: "chatml"
  max_length: 2048
  train_ratio: 0.8
  validation_ratio: 0.1
  test_ratio: 0.1

# Training
training:
  method: "qlora"
  base_model: "mistral:7b-instruct-q4_0"
  output_dir: "./fine_tuned_models"
  lora_r: 16
  lora_alpha: 32
  batch_size: 4
  learning_rate: 2e-4
  num_epochs: 3

# Evaluation
evaluation:
  metrics: ["perplexity", "accuracy", "bleu", "rouge"]
  test_prompts: ["What is machine learning?", "Explain neural networks"]

# Model deployment
deployment:
  ollama_base_url: "http://localhost:11434"
  auto_deploy: true
  model_name_prefix: "fine_tuned_"
```

## ğŸš€ Usage

### **1. Basic Fine-tuning Usage**
```python
from fine_tuning.data_collection.conversation_logger import ConversationLogger
from fine_tuning.data_preparation.formatter import TrainingDataFormatter

# Log conversations
logger = ConversationLogger()
logger.log_conversation("What is AI?", "AI is artificial intelligence...")

# Format data for training
formatter = TrainingDataFormatter("chatml")
training_pairs = formatter.create_training_pairs(conversations)
```

### **2. Data Collection from UI**
```python
# The conversation logger automatically logs conversations
# from the Streamlit UI when fine-tuning is enabled
```

### **3. Data Export and Preparation**
```python
from fine_tuning.data_collection.data_export import DataExporter

# Export conversations
exporter = DataExporter()
exports = exporter.export_all_formats(conversations)
```

### **4. Training Pipeline**
```python
# Training will be implemented in the training module
# This will include LoRA and QLoRA training capabilities
```

## ğŸ” How It Enhances the Chatbot

### **Without Fine-tuning:**
```
User: "What is our company's policy on remote work?"
LLM: [Generic response based on training data]
```

### **With Fine-tuning:**
```
User: "What is our company's policy on remote work?"
Fine-tuned LLM: [Specific response based on your company's actual policies]
```

## ğŸ“Š Performance Metrics

### **Training Metrics:**
- **Training Loss**: Reduction in loss during training
- **Validation Loss**: Model generalization performance
- **Training Time**: Time required for fine-tuning
- **Memory Usage**: Memory consumption during training

### **Evaluation Metrics:**
- **Perplexity**: Lower is better (measure of uncertainty)
- **Accuracy**: Higher is better (response quality)
- **BLEU Score**: Higher is better (text similarity)
- **Rouge Score**: Higher is better (text overlap)

### **Deployment Metrics:**
- **Model Loading Time**: Time to load fine-tuned model
- **Inference Speed**: Response generation speed
- **Memory Footprint**: Memory usage of fine-tuned model
- **Integration Success**: Successful deployment rate

## ğŸ› ï¸ Troubleshooting

### **Common Issues:**

#### **1. "No conversations to train on"**
- **Cause**: No conversation data collected
- **Solution**: Enable conversation logging and chat with the bot

#### **2. "Training data too small"**
- **Cause**: Insufficient conversation data
- **Solution**: Collect more conversations (recommend 100+ high-quality pairs)

#### **3. "Memory error during training"**
- **Cause**: Model too large for available memory
- **Solution**: Use QLoRA instead of LoRA, reduce batch size

#### **4. "Poor fine-tuning results"**
- **Cause**: Low-quality training data or wrong parameters
- **Solution**: Clean data better, adjust learning rate, increase epochs

### **Debug Mode:**
```python
# Enable debug logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Test individual components
from fine_tuning.data_collection.conversation_logger import ConversationLogger
logger = ConversationLogger()
stats = logger.get_conversation_stats()
print(stats)
```

## ğŸ”® Future Enhancements

### **Planned Features:**
1. **Continuous Learning**: Automatically retrain on new conversations
2. **Multi-modal Fine-tuning**: Support for images and audio
3. **Federated Learning**: Train across multiple devices
4. **Active Learning**: Selectively choose training data
5. **Hyperparameter Optimization**: Automatic parameter tuning
6. **Model Compression**: Reduce model size after fine-tuning

### **Advanced Features:**
1. **Domain-specific Fine-tuning**: Specialize for specific domains
2. **Multi-task Learning**: Train on multiple tasks simultaneously
3. **Few-shot Learning**: Learn from very few examples
4. **Meta-learning**: Learn to learn quickly
5. **Neural Architecture Search**: Find optimal model architecture

## ğŸ“š Learning Resources

### **Fine-tuning Concepts:**
- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
- [Parameter-Efficient Fine-tuning](https://huggingface.co/docs/peft)

### **Implementation Guides:**
- [Hugging Face Fine-tuning Tutorial](https://huggingface.co/docs/transformers/training)
- [PEFT Documentation](https://huggingface.co/docs/peft)
- [TRL (Transformer Reinforcement Learning)](https://huggingface.co/docs/trl)

### **Tools and Frameworks:**
- [Transformers Library](https://huggingface.co/docs/transformers)
- [Accelerate](https://huggingface.co/docs/accelerate)
- [BitsAndBytes](https://github.com/TimDettmers/bitsandbytes)

---

## ğŸ¯ Summary

The Fine-tuning System transforms our chatbot from a generic conversational AI into a **personalized, domain-specific assistant** that can:

âœ… **Learn** from your specific conversations  
âœ… **Adapt** to your communication style  
âœ… **Improve** performance on your use cases  
âœ… **Scale** to handle domain-specific tasks  
âœ… **Deploy** easily to your local environment  

This makes the chatbot much more useful for your specific needs and ensures it understands your context, terminology, and preferences.

---

*Fine-tuning System Documentation - Local Chatbot Project* ğŸ¯âœ¨



